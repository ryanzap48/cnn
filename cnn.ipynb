{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Installing torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'{sys.executable}' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "pkgs = [\n",
    "    \"torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\"\n",
    "]\n",
    "\n",
    "for p in pkgs:\n",
    "    print(f\"\\nInstalling {p} ...\")\n",
    "    !{sys.executable} -m pip install {p}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import re\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdFingerprintGenerator\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_template(template):\n",
    "    \"\"\"\n",
    "    Categorize interaction templates into high-level classes\n",
    "    \"\"\"\n",
    "    template_lower = template.lower()\n",
    "    \n",
    "    if 'adverse effects' in template_lower and 'risk or severity' in template_lower:\n",
    "        return 'adverse_effects_general'\n",
    "    \n",
    "    if 'cardiotoxic' in template_lower:\n",
    "        return 'cardiotoxicity'\n",
    "    elif 'nephrotoxic' in template_lower:\n",
    "        return 'nephrotoxicity'\n",
    "    elif 'hepatotoxic' in template_lower:\n",
    "        return 'hepatotoxicity'\n",
    "    elif 'neurotoxic' in template_lower:\n",
    "        return 'neurotoxicity'\n",
    "    elif 'myelosuppressive' in template_lower:\n",
    "        return 'myelosuppression'\n",
    "    elif 'ototoxic' in template_lower:\n",
    "        return 'ototoxicity'\n",
    "    \n",
    "    if 'metabolism' in template_lower:\n",
    "        return 'metabolism_change'\n",
    "    elif 'serum concentration' in template_lower:\n",
    "        if 'active metabolites' in template_lower:\n",
    "            return 'metabolite_concentration_change'\n",
    "        else:\n",
    "            return 'serum_concentration_change'\n",
    "    elif 'bioavailability' in template_lower:\n",
    "        return 'bioavailability_change'\n",
    "    elif 'absorption' in template_lower:\n",
    "        return 'absorption_change'\n",
    "    elif 'excretion rate' in template_lower:\n",
    "        return 'excretion_change'\n",
    "    elif 'protein binding' in template_lower:\n",
    "        return 'protein_binding_change'\n",
    "    \n",
    "    if 'qtc' in template_lower or 'qt' in template_lower:\n",
    "        return 'qtc_prolongation'\n",
    "    elif 'bradycardic' in template_lower:\n",
    "        return 'bradycardia'\n",
    "    elif 'tachycardic' in template_lower:\n",
    "        return 'tachycardia'\n",
    "    elif 'arrhythmogenic' in template_lower:\n",
    "        return 'arrhythmia'\n",
    "    elif 'hypotensive' in template_lower and 'orthostatic' not in template_lower:\n",
    "        return 'hypotension'\n",
    "    elif 'hypertensive' in template_lower:\n",
    "        return 'hypertension'\n",
    "    elif 'orthostatic hypotensive' in template_lower:\n",
    "        return 'orthostatic_hypotension'\n",
    "    elif 'antihypertensive' in template_lower:\n",
    "        return 'antihypertensive_effect'\n",
    "    elif 'vasoconstricting' in template_lower or 'vasopressor' in template_lower:\n",
    "        return 'vasoconstriction'\n",
    "    elif 'vasodilatory' in template_lower:\n",
    "        return 'vasodilation'\n",
    "    elif 'heart failure' in template_lower:\n",
    "        return 'heart_failure'\n",
    "    elif 'av block' in template_lower or 'atrioventricular' in template_lower:\n",
    "        return 'av_block'\n",
    "    \n",
    "    if 'anticoagulant' in template_lower:\n",
    "        return 'anticoagulation'\n",
    "    elif 'antiplatelet' in template_lower:\n",
    "        return 'antiplatelet_effect'\n",
    "    elif 'bleeding' in template_lower:\n",
    "        return 'bleeding_risk'\n",
    "    elif 'thrombogenic' in template_lower:\n",
    "        return 'thrombosis'\n",
    "\n",
    "    if 'hypokalemic' in template_lower:\n",
    "        return 'hypokalemia'\n",
    "    elif 'hyperkalemic' in template_lower or 'hyperkalemia' in template_lower:\n",
    "        return 'hyperkalemia'\n",
    "    elif 'hypocalcemic' in template_lower:\n",
    "        return 'hypocalcemia'\n",
    "    elif 'hypercalcemic' in template_lower:\n",
    "        return 'hypercalcemia'\n",
    "    elif 'hyponatremic' in template_lower:\n",
    "        return 'hyponatremia'\n",
    "    \n",
    "    if 'cns depressant' in template_lower:\n",
    "        if 'hypertensive' in template_lower:\n",
    "            return 'cns_depression_and_hypertension'\n",
    "        elif 'hypotensive' in template_lower:\n",
    "            return 'cns_depression_and_hypotension'\n",
    "        else:\n",
    "            return 'cns_depression'\n",
    "    elif 'neuroexcitatory' in template_lower:\n",
    "        return 'neuroexcitation'\n",
    "    elif 'sedative' in template_lower:\n",
    "        return 'sedation'\n",
    "    elif 'central neurotoxic' in template_lower:\n",
    "        return 'central_neurotoxicity'\n",
    "    elif 'serotonergic' in template_lower:\n",
    "        return 'serotonergic_effect'\n",
    "    elif 'antipsychotic' in template_lower:\n",
    "        return 'antipsychotic_effect'\n",
    "    \n",
    "    if 'hypoglycemic' in template_lower:\n",
    "        return 'hypoglycemia'\n",
    "    elif 'hyperglycemic' in template_lower:\n",
    "        return 'hyperglycemia'\n",
    "    \n",
    "    if 'respiratory depressant' in template_lower:\n",
    "        return 'respiratory_depression'\n",
    "    elif 'bronchodilatory' in template_lower:\n",
    "        return 'bronchodilation'\n",
    "    elif 'bronchoconstrictory' in template_lower:\n",
    "        return 'bronchoconstriction'\n",
    "    \n",
    "    if 'neuromuscular blocking' in template_lower:\n",
    "        return 'neuromuscular_blockade'\n",
    "    elif 'adverse neuromuscular' in template_lower:\n",
    "        return 'adverse_neuromuscular'\n",
    "    elif 'myopathic rhabdomyolysis' in template_lower:\n",
    "        return 'rhabdomyolysis'\n",
    "    \n",
    "    if 'therapeutic efficacy' in template_lower:\n",
    "        return 'therapeutic_efficacy'\n",
    "    elif 'analgesic' in template_lower:\n",
    "        return 'analgesic_effect'\n",
    "    elif 'anticholinergic' in template_lower:\n",
    "        return 'anticholinergic_effect'\n",
    "    elif 'immunosuppressive' in template_lower:\n",
    "        return 'immunosuppression'\n",
    "    elif 'diuretic' in template_lower:\n",
    "        return 'diuretic_effect'\n",
    "    elif 'stimulatory' in template_lower:\n",
    "        return 'stimulation'\n",
    "    \n",
    "    if 'ulcerogenic' in template_lower:\n",
    "        return 'ulcerogenic_effect'\n",
    "    elif 'constipating' in template_lower:\n",
    "        return 'constipation'\n",
    "\n",
    "    if 'fluid retaining' in template_lower:\n",
    "        return 'fluid_retention'\n",
    "    \n",
    "    if 'dermatologic' in template_lower:\n",
    "        return 'dermatologic_adverse'\n",
    "    \n",
    "    if 'hypersensitivity' in template_lower:\n",
    "        return 'hypersensitivity'\n",
    "    \n",
    "    if 'diagnostic agent' in template_lower:\n",
    "        return 'diagnostic_interference'\n",
    "    \n",
    "    return 'other_interaction'\n",
    "\n",
    "def extract_interaction_template(description, drug1, drug2):\n",
    "    template = description\n",
    "    template = re.sub(re.escape(drug1), 'DRUG_A', template, flags=re.IGNORECASE)\n",
    "    template = re.sub(re.escape(drug2), 'DRUG_B', template, flags=re.IGNORECASE)\n",
    "    template = re.sub(r'\\bincreas(e|ed|es|ing)\\b', 'DIRECTION', template, flags=re.IGNORECASE)\n",
    "    template = re.sub(r'\\bdecreas(e|ed|es|ing)\\b', 'DIRECTION', template, flags=re.IGNORECASE)\n",
    "    template = re.sub(r'\\b(enhance|enhanced|enhances|enhancing)\\b', 'DIRECTION', template, flags=re.IGNORECASE)\n",
    "    template = re.sub(r'\\b(reduc(e|ed|es|ing)|diminish(ed|es|ing)?|lower(ed|s|ing)?)\\b', 'DIRECTION', template, flags=re.IGNORECASE)\n",
    "    template = re.sub(r'\\b(elevat(e|ed|es|ing)|rais(e|ed|es|ing))\\b', 'DIRECTION', template, flags=re.IGNORECASE)\n",
    "    return template\n",
    "\n",
    "\"\"\"\n",
    "df['Template'] = df.apply(\n",
    "    lambda row: extract_interaction_template(\n",
    "        row['Interaction Description'], \n",
    "        row['Drug 1'], \n",
    "        row['Drug 2']\n",
    "    ), \n",
    "    axis=1\n",
    ")\n",
    "print(f\"Created {df['Template'].nunique()} unique templates\")\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "# Categorize the templates\n",
    "df['Interaction_Category'] = df['Template'].apply(categorize_template)\n",
    "print(f\"\\nCreated {df['Interaction_Category'].nunique()} base categories\")\n",
    "\n",
    "# Combine category + direction\n",
    "df['Category_With_Direction'] = df['Interaction_Category'] + '_' + df['Direction']\n",
    "print(f\"Combined into {df['Category_With_Direction'].nunique()} final categories\")\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "for i, label in enumerate(le.classes_):\n",
    "    count = (df['Direction'] == label).sum()\n",
    "    # Parse out category and direction for display\n",
    "    if '_increased' in label:\n",
    "        category = label.replace('_increased', '')\n",
    "        direction = '↑'\n",
    "    elif '_decreased' in label:\n",
    "        category = label.replace('_decreased', '')\n",
    "        direction = '↓'\n",
    "    elif '_neutral' in label:\n",
    "        category = label.replace('_neutral', '')\n",
    "        direction = '='\n",
    "    elif '_mixed' in label:\n",
    "        category = label.replace('_mixed', '')\n",
    "        direction = '±'\n",
    "    else:\n",
    "        category = label\n",
    "        direction = '?'\n",
    "\n",
    "    print(f\"  {i:3d}. [{direction}] {category:.<45} {count:>6,} samples\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_direction(description):\n",
    "    desc = description.lower()\n",
    "    \n",
    "    if re.search(r\"\\bincreas(e|ed)\\b\", desc):\n",
    "        return \"increased\"\n",
    "    \n",
    "    if re.search(r\"\\bdecreas(e|ed)\\b|\\breduced\\b\", desc):\n",
    "        return \"decreased\"\n",
    "    \n",
    "    return \"other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Direction\n",
      "increased    128533\n",
      "decreased     61399\n",
      "Name: count, dtype: int64\n",
      "Number of classes for training: 2\n"
     ]
    }
   ],
   "source": [
    "# add interaction label to dataset\n",
    "\n",
    "df = pd.read_csv('drug_interactions_cleaned.csv')\n",
    "\n",
    "df['Direction'] = df['Interaction Description'].apply(extract_direction)\n",
    "print(df['Direction'].value_counts())\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['Interaction_Label'] = le.fit_transform(df['Direction'])\n",
    "\n",
    "num_classes = len(le.classes_)\n",
    "print(f\"Number of classes for training: {num_classes}\")\n",
    "\n",
    "df.to_csv('drug_interactions_direction.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smiles_to_fingerprint(smiles, radius=2, nBits=2048):\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            return None\n",
    "        gen = rdFingerprintGenerator.GetMorganGenerator(radius=radius, fpSize=nBits)\n",
    "        fp = gen.GetFingerprint(mol)\n",
    "        return np.array(fp)\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 496/1656 [00:00<00:01, 592.93it/s][17:05:41] WARNING: not removing hydrogen atom without neighbors\n",
      "[17:05:41] WARNING: not removing hydrogen atom without neighbors\n",
      " 61%|██████    | 1011/1656 [00:01<00:01, 634.72it/s][17:05:42] WARNING: not removing hydrogen atom without neighbors\n",
      "[17:05:42] WARNING: not removing hydrogen atom without neighbors\n",
      "100%|██████████| 1656/1656 [00:02<00:00, 619.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed: 0 rows with failed fingerprints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('drug_interactions_direction.csv')\n",
    "\n",
    "unique_smiles = pd.concat([df['Drug1_SMILES'], df['Drug2_SMILES']]).unique()\n",
    "\n",
    "smiles_to_fp_dict = {}\n",
    "for smiles in tqdm(unique_smiles):\n",
    "    fp = smiles_to_fingerprint(smiles)\n",
    "    smiles_to_fp_dict[smiles] = fp\n",
    "\n",
    "df['Drug1_FP'] = df['Drug1_SMILES'].map(smiles_to_fp_dict)\n",
    "df['Drug2_FP'] = df['Drug2_SMILES'].map(smiles_to_fp_dict)\n",
    "\n",
    "before_removal = len(df)\n",
    "df = df.dropna(subset=['Drug1_FP', 'Drug2_FP'])\n",
    "print(f\"Removed: {before_removal - len(df)} rows with failed fingerprints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = np.stack(df['Drug1_FP'].values).astype(np.float32)\n",
    "X2 = np.stack(df['Drug2_FP'].values).astype(np.float32)\n",
    "y = df['Interaction_Label'].values.astype(np.int64)\n",
    "\n",
    "X1_train, X1_test, X2_train, X2_test, y_train, y_test = train_test_split(\n",
    "    X1, X2, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDIDataset(Dataset):\n",
    "    def __init__(self, drug1_fps, drug2_fps, labels):\n",
    "        self.drug1_fps = torch.FloatTensor(drug1_fps)\n",
    "        self.drug2_fps = torch.FloatTensor(drug2_fps)\n",
    "        self.labels = torch.LongTensor(labels)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.drug1_fps[idx], self.drug2_fps[idx], self.labels[idx]\n",
    "\n",
    "train_dataset = DDIDataset(X1_train, X2_train, y_train)\n",
    "test_dataset = DDIDataset(X1_test, X2_test, y_test)\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDIPredictor(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(DDIPredictor, self).__init__()\n",
    "        \n",
    "        self.drug_encoder = nn.Sequential(\n",
    "            nn.Conv1d(1, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.MaxPool1d(2),\n",
    "            \n",
    "            nn.Conv1d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.MaxPool1d(2),\n",
    "\n",
    "            nn.Conv1d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.AdaptiveMaxPool1d(1)\n",
    "        )\n",
    "        \n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(512 * 2, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, drug1, drug2):\n",
    "        drug1 = drug1.unsqueeze(1)  # (batch, 1, 2048)\n",
    "        drug2 = drug2.unsqueeze(1)  # (batch, 1, 2048)\n",
    "    \n",
    "        drug1_features = self.drug_encoder(drug1).squeeze(-1)  # (batch, 512)\n",
    "        drug2_features = self.drug_encoder(drug2).squeeze(-1)  # (batch, 512)\n",
    "        \n",
    "        combined = torch.cat([drug1_features, drug2_features], dim=1)  # (batch, 1024)\n",
    "        output = self.fc_layers(combined)\n",
    "\n",
    "        return output\n",
    "\n",
    "model = DDIPredictor(num_classes=num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pbar = tqdm(loader, desc='Training')\n",
    "    for drug1, drug2, labels in pbar:\n",
    "        drug1, drug2, labels = drug1.to(device), drug2.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(drug1, drug2)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * drug1.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        pbar.set_postfix({'loss': loss.item(), 'acc': correct/total})\n",
    "    \n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for drug1, drug2, labels in loader:\n",
    "            drug1, drug2, labels = drug1.to(device), drug2.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(drug1, drug2)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * drug1.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 13/2375 [01:04<3:14:20,  4.94s/it, loss=0.717, acc=0.53] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[59]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[32m     15\u001b[39m     current_lr = optimizer.param_groups[\u001b[32m0\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     train_loss, train_acc = \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m     val_loss, val_acc = evaluate(model, test_loader, criterion, device)\n\u001b[32m     20\u001b[39m     history[\u001b[33m'\u001b[39m\u001b[33mtrain_loss\u001b[39m\u001b[33m'\u001b[39m].append(train_loss)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[57]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mtrain_epoch\u001b[39m\u001b[34m(model, loader, criterion, optimizer, device)\u001b[39m\n\u001b[32m      9\u001b[39m drug1, drug2, labels = drug1.to(device), drug2.to(device), labels.to(device)\n\u001b[32m     11\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdrug1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdrug2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m loss = criterion(outputs, labels)\n\u001b[32m     16\u001b[39m loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Python/3.12/lib/python/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Python/3.12/lib/python/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[55]\u001b[39m\u001b[32m, line 37\u001b[39m, in \u001b[36mDDIPredictor.forward\u001b[39m\u001b[34m(self, drug1, drug2)\u001b[39m\n\u001b[32m     34\u001b[39m drug2 = drug2.unsqueeze(\u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# (batch, 1, 2048)\u001b[39;00m\n\u001b[32m     36\u001b[39m drug1_features = \u001b[38;5;28mself\u001b[39m.drug_encoder(drug1).squeeze(-\u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# (batch, 512)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m drug2_features = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdrug_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdrug2\u001b[49m\u001b[43m)\u001b[49m.squeeze(-\u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# (batch, 512)\u001b[39;00m\n\u001b[32m     39\u001b[39m combined = torch.cat([drug1_features, drug2_features], dim=\u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# (batch, 1024)\u001b[39;00m\n\u001b[32m     40\u001b[39m output = \u001b[38;5;28mself\u001b[39m.fc_layers(combined)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Python/3.12/lib/python/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Python/3.12/lib/python/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Python/3.12/lib/python/site-packages/torch/nn/modules/container.py:244\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    242\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    243\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m244\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    245\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Python/3.12/lib/python/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Python/3.12/lib/python/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Python/3.12/lib/python/site-packages/torch/nn/modules/pooling.py:145\u001b[39m, in \u001b[36mMaxPool1d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    144\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor):\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmax_pool1d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    147\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    148\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[43m        \u001b[49m\u001b[43mceil_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mceil_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    152\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_indices\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreturn_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    153\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Python/3.12/lib/python/site-packages/torch/_jit_internal.py:627\u001b[39m, in \u001b[36mboolean_dispatch.<locals>.fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    625\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m if_true(*args, **kwargs)\n\u001b[32m    626\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m627\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mif_false\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Python/3.12/lib/python/site-packages/torch/nn/functional.py:737\u001b[39m, in \u001b[36m_max_pool1d\u001b[39m\u001b[34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stride \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    736\u001b[39m     stride = torch.jit.annotate(\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mint\u001b[39m], [])\n\u001b[32m--> \u001b[39m\u001b[32m737\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmax_pool1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mceil_mode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "best_val_acc = 0.0\n",
    "\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_loss': [],\n",
    "    'val_acc': [],\n",
    "    'learning_rate': []\n",
    "}\n",
    "\n",
    "print(\"Starting training...\\n\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc = evaluate(model, test_loader, criterion, device)\n",
    "    \n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['learning_rate'].append(current_lr)\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] LR: {current_lr:.6f}\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"  Val Loss:   {val_loss:.4f} | Val Acc:   {val_acc:.4f}\")\n",
    "    \n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), 'best_cnn_model.pth')\n",
    "        print(f\"New best model saved (Val Acc: {val_acc:.4f})\")\n",
    "    print()\n",
    "\n",
    "print(\"\\nTraining complete!\")\n",
    "print(f\"Best validation accuracy: {best_val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Accuracy plot\n",
    "axes[0].plot(history['train_acc'], label='Train Accuracy')\n",
    "axes[0].plot(history['val_acc'], label='Val Accuracy')\n",
    "axes[0].set_title('Model Accuracy')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Loss plot\n",
    "axes[1].plot(history['train_loss'], label='Train Loss')\n",
    "axes[1].plot(history['val_loss'], label='Val Loss')\n",
    "axes[1].set_title('Model Loss')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "best_epoch = np.argmax(history['val_acc'])\n",
    "print(f\"Best epoch: {best_epoch + 1}\")\n",
    "print(f\"Best validation accuracy: {history['val_acc'][best_epoch]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set with best model\n",
    "test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
    "\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Final Test Accuracy: {test_acc:.4f} ({test_acc*100:.2f}%)\")\n",
    "print(f\"Final Test Loss: {test_loss:.4f}\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smiles_to_fingerprint(smiles, radius=2, nBits=2048):\n",
    "    \"\"\"Convert SMILES to Morgan fingerprint\"\"\"\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            return None\n",
    "        gen = rdFingerprintGenerator.GetMorganGenerator(radius=radius, fpSize=nBits)\n",
    "        fp = gen.GetFingerprint(mol)\n",
    "        return np.array(fp, dtype=np.float32)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def predict_interaction(drug1_smiles, drug2_smiles, top_k=3):\n",
    "    \"\"\"Predict interaction between two drugs\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Convert to fingerprints\n",
    "    fp1 = smiles_to_fingerprint(drug1_smiles)\n",
    "    fp2 = smiles_to_fingerprint(drug2_smiles)\n",
    "    \n",
    "    if fp1 is None or fp2 is None:\n",
    "        return [(\"Invalid SMILES\", 0.0)]\n",
    "    \n",
    "    # Convert to tensors\n",
    "    fp1 = torch.FloatTensor(fp1).unsqueeze(0).to(device)\n",
    "    fp2 = torch.FloatTensor(fp2).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        outputs = model(fp1, fp2)\n",
    "        probabilities = torch.softmax(outputs, dim=1)[0]\n",
    "    \n",
    "    # Get top k predictions\n",
    "    top_probs, top_indices = torch.topk(probabilities, top_k)\n",
    "    \n",
    "    results = []\n",
    "    for prob, idx in zip(top_probs, top_indices):\n",
    "        interaction_type = le.inverse_transform([idx.item()])[0]\n",
    "        results.append((interaction_type, prob.item()))\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"✓ Prediction function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test predictions\n",
    "print(\"Testing predictions on random samples:\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "test_samples = df.sample(5, random_state=42)\n",
    "\n",
    "for idx, row in test_samples.iterrows():\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Drug 1: {row['Drug 1']}\")\n",
    "    print(f\"Drug 2: {row['Drug 2']}\")\n",
    "    print(f\"\\nActual Interaction:\")\n",
    "    print(f\"  {row['Interaction Description']}\")\n",
    "    \n",
    "    predictions = predict_interaction(row['Drug1_SMILES'], row['Drug2_SMILES'], top_k=3)\n",
    "    \n",
    "    print(f\"\\nTop 3 Predictions:\")\n",
    "    for i, (interaction, conf) in enumerate(predictions, 1):\n",
    "        match = \"✓\" if interaction == row['Interaction Description'] else \"✗\"\n",
    "        print(f\"  {i}. [{match}] {interaction}\")\n",
    "        print(f\"      Confidence: {conf:.2%}\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
